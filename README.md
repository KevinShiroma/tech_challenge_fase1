# Tech Challenge - Fase 1: Sistema Inteligente de Suporte ao Diagn√≥stico

Este reposit√≥rio cont√©m o projeto da **Fase 1** do Tech Challenge (P√≥s-Tech Data Engineering). O objetivo √© desenvolver um pipeline de dados *end-to-end* e um modelo de Machine Learning para auxiliar no diagn√≥stico de riscos √† sa√∫de mental, utilizando a arquitetura Medalh√£o.

## Link Para youtube
link https://youtu.be/lHG56KRjrpM

## üìã Sobre o Projeto

O sistema processa dados m√©dicos para classificar se um paciente possui ou n√£o risco de desenvolver condi√ß√µes de sa√∫de mental. A solu√ß√£o foi adaptada de um ambiente Databricks para uma arquitetura local reprodut√≠vel utilizando Docker e Python.

### Arquitetura de Dados
O pipeline segue a arquitetura **Medallion** (Bronze, Silver, Gold):
1.  **Bronze (Raw):** Ingest√£o dos dados brutos diretamente da API do Kaggle.
2.  **Silver (Cleaned):** Limpeza de nulos, normaliza√ß√£o de colunas categ√≥ricas e convers√£o de tipos (Spark).
3.  **Gold (Curated):** Engenharia de features (*One-Hot Encoding*, *Label Encoding*) pronta para o consumo do modelo de ML.

### Tecnologias Utilizadas
* **Linguagem:** Python 3.9
* **Processamento de Dados:** PySpark & Pandas
* **Machine Learning:** Scikit-Learn (KNN e Random Forest)
* **Visualiza√ß√£o:** Matplotlib & Seaborn
* **Ambiente:** Docker & VS Code
* **Fonte de Dados:** [Kaggle - Mental Health Dataset](https://www.kaggle.com/datasets/mahdimashayekhi/mental-health)

---

## üìÇ Estrutura do Reposit√≥rio

```text
tech-challenge-fase1/
‚îÇ
‚îú‚îÄ‚îÄ Dockerfile                  # Receita para criar o ambiente (Python + Java/Spark)
‚îú‚îÄ‚îÄ requirements.txt            # Lista de bibliotecas necess√°rias
‚îú‚îÄ‚îÄ README.md                   # Documenta√ß√£o do projeto
‚îú‚îÄ‚îÄ .gitignore                  # Arquivos ignorados (dados e caches)
‚îÇ
‚îú‚îÄ‚îÄ src/                        # C√≥digo-fonte
‚îÇ   ‚îú‚îÄ‚îÄ 01_etl.py               # Script de ETL: Baixa do Kaggle e processa at√© a camada Gold
‚îÇ   ‚îî‚îÄ‚îÄ 02_analise_interativa.py # Script para gera√ß√£o de gr√°ficos e modelos (Janela Interativa)
‚îÇ
‚îî‚îÄ‚îÄ data/                       # [GitIgnored] Pasta local onde os dados processados ser√£o salvos
    ‚îú‚îÄ‚îÄ bronze/
    ‚îú‚îÄ‚îÄ silver/
    ‚îî‚îÄ‚îÄ gold/
```

## üöÄ Guia de Execu√ß√£o

Para garantir que o projeto rode em qualquer m√°quina sem conflitos de depend√™ncia, utilizamos Docker para a prepara√ß√£o dos dados pesados.

### Pr√©-requisitos
* Docker Desktop instalado e rodando.
* VS Code com a extens√£o Python instalada.

### Passo 1: Construir a Imagem Docker
Abra o terminal na raiz do projeto e execute o comando abaixo para criar a imagem com Spark e Python configurados:

```bash
docker build -t tech-challenge-health .
```

### Passo 2: Executar o Pipeline ETL (Ingest√£o e Tratamento)
Este comando iniciar√° um container que baixa os dados do Kaggle, processa as camadas Bronze/Silver e salva a camada Gold (Parquet) na sua pasta local `data/`.

**No Linux/Mac:**
```bash
docker run --rm -v $(pwd)/data:/app/data tech-challenge-health
```

**No Windows (PowerShell):**
```powershell
docker run --rm -v ${PWD}/data:/app/data tech-challenge-health
```

> **Aten√ß√£o:** O download inicial do dataset e depend√™ncias do Java pode levar alguns minutos. Aguarde at√© aparecer a mensagem no terminal: *"Dados prontos para plotagem em: data/gold"*.

### Passo 3: An√°lise e Gera√ß√£o de Gr√°ficos (Local)
Ap√≥s a execu√ß√£o do Passo 2, a pasta `data/gold` estar√° populada com os dados tratados. Agora, voc√™ deve rodar a an√°lise interativa no VS Code para visualizar os gr√°ficos.

1. Instale as depend√™ncias locais (opcional, se n√£o estiver usando Dev Container):
   ```bash
   pip install -r requirements.txt
   ```
2. Abra o arquivo `src/02_analise_interativa.py` no VS Code.
3. No c√≥digo, voc√™ ver√° c√©lulas marcadas com `#%%`.
4. Clique na op√ß√£o **"Run Cell"** (ou "Executar C√©lula") que aparece logo acima de cada bloco de c√≥digo.
5. Os gr√°ficos interativos aparecer√£o na janela lateral (*Interactive Window*).

---

## ‚úíÔ∏è Autor - Kevin Makoto Shiroma
Projeto desenvolvido como parte da avalia√ß√£o do **Tech Challenge - Fase 1**.
